module examples.mnist

import data.tensor
import ml.nn.conv2d
import ml.nn.maxpool2d
import ml.nn.softmax
import ml.nn.relu
import ml.vision.datasets

fun mnist_model(input:tensor<f32, @[1,1,28,28]>, \
          conv1:tensor<f32, @[32,1,3,3]>,  \
	  conv2:tensor<f32, @[64,32,3,3]>) : tensor<f32, @[1,64*12*12]> {
    val x = conv2d(input, conv1)
    val x = relu(x)
    val x = conv2d(x, conv2)
    val x = relu(x)
    val x = maxpool2d<2,2>(x)
    val x = relu(x)
    val x = reshape<@[1, 64*12*12]>(x)
    val x = log_softmax(x,1)
    x
}

diff mnist_model wrt (conv1, conv2) = auto

fun main() : io unit {
    val ds = mnist("./data", true)
    var conv1 = full<@[32,1,3,3]>(1.0, [])
    var conv2 = full<@[64,32,3,3]>(1.0, [])
    var input = full<@[1,1,28,28]>(1.0, [])
    var grads = full<@[1,64*12*12]>(1.0, [])
    val (conv1_grad, conv2_grad) = diff mnist_model(input, conv1, conv2, grads)
    print(conv1_grad)
    print(conv2_grad)
    // foreach(ds, fn(d : tensor<f32, @[1,28,28]>, i : i32) : io unit {
    //     if (i < 1) {
    //         val dd = reshape<@[1,1,28,28]>(d)
    //         print(mnist_model(dd, conv1, conv2))
	   //  //print(dd)
    //     } else {
    //         unit
    //     }
    // })
}
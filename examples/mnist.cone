module examples.mnist

import data.tensor
import ml.nn.conv2d
import ml.nn.maxpool2d
import ml.nn.softmax
import ml.nn.relu
import ml.nn.dropout
import ml.nn.fc
import ml.optimizer.loss
import ml.vision.datasets

alias mnist_weights = (tensor<f32, @[32,1,3,3]>,  \
	                   tensor<f32, @[64,32,3,3]>, \
                       tensor<f32, @[128,9216]>,  \
                       tensor<f32, @[128]>,       \
                       tensor<f32, @[10,128]>,    \
                       tensor<f32, @[10]>)

fun mnist_train(input:tensor<f32, @[1,1,28,28]>, \
                target:tensor<i32, @[1]>,         \
                weights:mnist_weights) : f32 {
    val (conv1, conv2, fcw1, fcb1, fcw2, fcb2) = weights
    val x = conv2d(input, conv1)
    val x = relu(x)
    val x = conv2d(x, conv2)
    val x = relu(x)
    val x = maxpool2d<2,2>(x)
    val x = dropout(x, 0.25)
    val x = reshape<@[1, 9216]>(x)
    val x = fc(x, fcw1, fcb1)
    val x = relu(x)
    val x = dropout(x, 0.5)
    val x = fc(x, fcw2, fcb2)
    val x = log_softmax(x,1)
    nll_loss(x, target)
}

diff mnist_train wrt (weights) = auto

fun main() : io unit {
    val ds = mnist("./data", true)
    var weights = (full<@[32,1,3,3]>(1.0, []),  \
                   full<@[64,32,3,3]>(1.0, []), \
                   full<@[128,9216]>(1.0, []),  \
                   full<@[128]>(1.0, []),       \
                   full<@[10,128]>(1.0, []),    \
                   full<@[10]>(1.0, []))
    val rate = 0.1
    foreach(ds, fn(d : (tensor<f32, @[1,28,28]>, i32), i : i32) : unit {
        if (i < 1) {
            val (data, target) = d
            val data = reshape<@[1,1,28,28]>(data)
            val target = full<@[1]>(target, [])
            val (conv1_grad, conv2_grad, fcw1_grad, fcb1_grad, fcw2_grad, fcb2_grad) = diff mnist_train(data, target, weights, 1.0)
            weights = weights - (conv1_grad * full<@[32,1,3,3]>(rate, []),  \
                                 conv2_grad * full<@[64,32,3,3]>(rate, []), \
                                 fcw1_grad * full<@[128,9216]>(rate, []),   \
                                 fcb1_grad * full<@[128]>(rate, []),        \
                                 fcw2_grad * full<@[10,128]>(rate, []),     \
                                 fcb2_grad * full<@[10]>(rate, []))
        } else {
            unit
        }
    })
    print("finished")
}
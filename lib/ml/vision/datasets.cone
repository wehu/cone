module ml.vision.datasets

import data.tensor

type dataset<t, shape: @[num]>

effect iterator<t, n:num, shape:@[num]> {
    fun reset(dataset<t, n|shape>) : unit
    fun next(dataset<t, n|shape>) : (tensor<t, n|shape>, tensor<i32, @[n]>)
}

fun len<t, shape: @[num]>(ds : dataset<t, shape>) : i32 {
    inline_python<i32>("""
____result = len(ds[0])
    """)
}

fun foreach<t, n:num, shape:@[num]>[e](ds : dataset<t, n|shape>, f : ((tensor<t, n|shape>, tensor<i32, @[n]>), i32) -> e unit) : e unit {
    var i = 0
    val size = len(ds)
    handle iterator<t, n, shape> {
        reset(ds)
        while i < size {
            f(next(ds), i)
            i = i + 1
        }
    } with {
        fun reset(ds : dataset<t, n|shape>) {
            inline_python<unit>("""
ds[1] = iter(ds[0])
            """)
            resume(unit)
        }
        fun next(ds : dataset<t, n|shape>) {
            resume(inline_python<(tensor<t, n|shape>, tensor<i32, @[n]>)>("""
data = next(ds[1])
____result = (data[0].numpy().astype(float), data[1].numpy())
            """))
        }
    }
}

fun mnist<n:num>(dir : str, train : bool) : dataset<f32, @[n, 1, 28, 28]> {
    inline_python<dataset<f32, @[n, 1, 28, 28]>, @[n]>("""
import torch
from torchvision import datasets, transforms
transform=transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
        ])
N = ____typeargs[1][0]
ds = datasets.MNIST(dir, train=train, transform=transform, download=True)
dl = torch.utils.data.DataLoader(ds, batch_size=N)
____result = [dl, iter(dl)]
    """)
}
module ml.optimizer.loss

import data.tensor

fun nll_loss<n:num, c:num, t>(input:tensor<t, @[n, c]>, target:tensor<t, @[n]>) : t {
    inline_python<t>("""
import torch
import torch.nn.functional as F
____result = F.nll_loss(torch.from_numpy(input), torch.from_numpy(target)).numpy()
    """)    
}

diff nll_loss wrt(input) = nll_loss_diff

fun nll_loss_diff<n:num, c:num, t>(input:tensor<t, @[n, c]>, target:tensor<t, @[n]>, output_diff:t) : tensor<t, @[n, c]> {
    inline_python<tensor<t, @[n, c]>>("""
import torch
import torch.nn.functional as F
a = torch.tensor(input, requires_grad=True)
p = torch.nll_loss(a, torch.from_numpy(target))
p.backward(torch.from_numpy(output_diff))
____result = a.grad.numpy()
    """)    
}